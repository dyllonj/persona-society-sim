template: run.fast.yaml
run_id: "study100"
model_name: "meta-llama/Llama-3-70b-instruct"
population: 100
steps: 500
seed: 42
steering:
  enabled: true
  strength: 1.0
  coefficients:
    E: 0.9
    A: 0.7
    C: 0.8
    O: 0.5
    N: 0.0
  vector_norm:
    E: 1.0
    A: 1.0
    C: 1.0
    O: 1.0
    N: 1.0
  metadata_files:
    personas: configs/personas.bigfive.yaml
    vectors: configs/steering.layers.yaml  # metadata-aware vector loader
scenario: "project_market_mix"
logging:
  db_url: "postgresql+psycopg://persona:persona@localhost:5432/persona"
  parquet_dir: "./storage/dumps/study100"
meta_orchestrator:
  enabled: true
  playbook_file: configs/meta.playbook.yaml
safety:
  alpha_clip: 1.0
  toxicity_threshold: 0.35
  governor_backoff: 0.15
inference:
  temperature: 0.65
  top_p: 0.92
  max_new_tokens: 160
optimization:
  reflect_every_n_ticks: 10  # Reflect every 10 ticks for better planning
